import numpy as np
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader,Dataset
import cv2 as cv
import helper
from torchsummary import summary
import torch.optim as optim
from tqdm.notebook import tqdm
import time
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow as imshow

!nvidia-smi

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
torch.cuda.empty_cache()
device

from google.colab import drive
drive.mount('/content/drive')

class stool(Dataset):
    def __init__(self,ipath,labels,size):
        self.impath=ipath
        self.images=os.listdir(self.impath)
        self.labels=labels
        self.size=size
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self,index):
        
        x= cv.imread(os.path.join(self.impath,self.images[index]),1)
        x=cv.resize(x,self.size)
        x= np.transpose(x, (2, 0, 1))
        
        x=torch.from_numpy(x).float()
        x=x/255
        
        y=cv.imread(os.path.join(self.labels,self.images[index]),0)
        
        y=cv.resize(y,self.size)
        y=np.expand_dims(y,axis=-1)
        y= np.transpose(y, (2, 0, 1))
        y= torch.from_numpy(y).float()
        y=y/255
        
        return x,y
    

def data_load(batch,size=(512,512)):
  batch=batch
  size=(512,512)
  timagesp='\path\to\folder'
  tlabelsp='\path\to\folder'

  trainl=stool(timagesp,tlabelsp,size=size)
  tl=DataLoader(trainl,batch_size=batch,shuffle=1)

  vim='\path\to\folder'
  vla='\path\to\folder'

  vald=stool(vim,vla,size=size)
  vl=DataLoader(vald,batch_size=batch,shuffle=1)
  print('valid_data_size=',len(vald),'....train_data_size=',len(trainl))
  return tl,vl

def down(in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            # nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),nn.Dropout2d(p=0.3),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

class Unet(nn.Module):
    def __init__(self):
        super(Unet, self).__init__()
        self.d1 = down(3,16)
        self.d2 = down(16,32)
        self.d3 = down(32,64)
        self.d4 = down(64,128)
        self.d5 = down(128,256)
        self.d6 = down(256,512)
        self.m  = nn.MaxPool2d(2)
        self.up1 = nn.ConvTranspose2d(256,128,2,2)
        self.up2 = nn.ConvTranspose2d(128,64,2,2)
        self.up3 = nn.ConvTranspose2d(64,32,2,2)
        self.up4 = nn.ConvTranspose2d(32,16,2,2)
        self.up5 = nn.ConvTranspose2d(512,256,2,2)
        self.u1 = down(256,128)
        self.u2 = down(128,64)
        self.u3 = down(64,32)
        self.u4 = down(32,16)
        self.u5 = down(512,256)
        self.last=nn.Conv2d(16,1,1)
        self.sig= nn.Sigmoid()
        self.init_weights()
    
     
    def forward(self,x):
#         print(x.shape)
        c1=self.d1(x)
        c1d=self.m(c1)
        
        c2=self.d2(c1d)
        c2d=self.m(c2)
        
        c3=self.d3(c2d)
        c3d=self.m(c3)
        
        c4=self.d4(c3d)
        c4d=self.m(c4)
        
        c5=self.d5(c4d)
        c5d=self.m(c5)
        
        c6=self.d6(c5d)
        
        up=self.up5(c6)
        con=torch.cat([up,c5],dim=1)
        u0c=self.u5(con)
        
        up=self.up1(u0c)
        con1=torch.cat([up,c4],dim=1)
        u1c=self.u1(con1)
        
        up=self.up2(u1c)
        con2=torch.cat([up,c3],dim=1)
        u2c=self.u2(con2)
        
        up=self.up3(u2c)
        con3=torch.cat([up,c2],dim=1)
        u3c=self.u3(con3)
        
        up=self.up4(u3c)
        con4=torch.cat([up,c1],dim=1)
        u4c=self.u4(con4)
        
        l=self.last(u4c)
        out=self.sig(l)
        return out
 
    def init_weights(self):
        for m in self.modules():
            if isinstance(m,nn.Conv2d):
                nn.init.kaiming_uniform_(m.weight)
                
                if m.bias is not None:
                    nn.init.constant_(m.bias,0.001)
            
            elif isinstance(m,nn.BatchNorm2d):
                nn.init.constant_(m.weight,1)
                nn.init.constant_(m.bias,0.01)  

u=Unet()
u=u.to(device)
# u.load_state_dict(torch.load('/content/drive/MyDrive/Computer Vision/Latest CV_vamsh/Segmentation_Data/weights/29Mar/adamnbn.pt'))
summary(u, input_size=(3,512,512))

def dice(pred, target):
    smooth = 1e-1
#     print(pred.shape,target.shape)
    predf = pred.view(-1)
    targetf = target.view(-1)
    intersection = (predf * targetf).sum()
    d=((2 * intersection + smooth) /
              (predf.sum() + targetf.sum() + smooth))
    return d
        
def dc_loss(pred,target):
    return 1-dice(pred,target)

def plot(epochs,train_loss_epoch,val_loss_epoch,train_dice_epoch,val_dice_epoch):
  plt.xlim(0,epochs)
  plt.plot(train_loss_epoch, label='Training loss')
  plt.plot(val_loss_epoch, label='Validation loss')
  plt.legend(frameon=False)
  plt.show() 
  plt.xlim(0,epochs)
  plt.plot(train_dice_epoch, label='Training dice')
  plt.plot(val_dice_epoch, label='Validation dice')
  plt.legend(frameon=False)
  plt.show() 

def train(model,epochs,batch):
    trainload,valload=data_load(batch)
    train_start=time.time()
    train_loss_epoch=[]
    val_loss_epoch=[]
    train_dice_epoch=[]
    val_dice_epoch=[]
    minval=float('inf')
    for epoch in range(epochs):
        torch.cuda.empty_cache()
        epoch_start=time.time()
        train_loss=[]
        val_loss=[]
        train_dice=[]
        val_dice=[]
        
        model.train()
        
        for batch,(images,targets) in tqdm(enumerate(trainload), total = len(trainload), leave = False):
            images=images.to(device)
            targets=targets.to(device)
            
            model.zero_grad()
            out=model(images)
            loss=dc_loss(out,targets)
            dice_co=dice(out,targets)
            loss.backward()
            optimizer.step()
            
            train_loss.append(loss.item())
            train_dice.append(dice_co.item())
            
            
            #############
#               VALID
            #############
    
        model.eval()
        
        with torch.no_grad():
            for vbatch,(vimages,vtargets) in tqdm(enumerate(valload), total = len(valload), leave = False) :
                vimages=vimages.to(device)
                vtargets=vtargets.to(device)


                vout=model(vimages.detach())
                vloss=dc_loss(vout,vtargets)
                vdice=dice(vout,vtargets)

                val_loss.append(vloss.item())
                val_dice.append(vdice.item())
            
            train_loss_epoch.append(np.average(train_loss))
            val_loss_epoch.append(np.average(val_loss))
            train_dice_epoch.append(np.average(train_dice))
            val_dice_epoch.append(np.average(val_dice))
            
            print('for epoch: '+ str(epoch) +
                  ' validation loss ' + str(np.average(val_loss)) + ' train loss ' + str(np.average(train_loss)) + 
                  ' validation dice ' +  str(np.average(val_dice)) + ' train dice ' + str(np.average(train_dice)))
            plot(epochs,train_loss_epoch,val_loss_epoch,train_dice_epoch,val_dice_epoch)
            torch.save({
                'epoch': epoch,
              'model_state_dict': model.state_dict(),
              'optimizer_state_dict': optimizer.state_dict(),
              'loss': np.average(train_loss),
              }, '/content/drive/MyDrive/Computer Vision/Latest CV_vamsh/Segmentation_Data/weights/2048_512/cp/27Jul/adambn.pt')
            if epoch > 10:                
                if minval > np.average(val_loss):
                    minval =np.average(val_loss)
                    print('minval' + str(np.average(val_loss)) + ' saving model')
                    torch.save(model.state_dict(), '/content/drive/MyDrive/Computer Vision/Latest CV_vamsh/Segmentation_Data/weights/2048_512/weights/27Jul/adamsbn.pt')
#                 if train_loss_epoch[-1] > train_loss_epoch[-2]:
#                     torch.save(model.state_dict(), 'pytorch_dice.pt')
#                     earlystopping = True 
#                     if earlystopping:
#                         break
                
            # if device.type == 'cuda' and (epoch%10==0):
            #     print(torch.cuda.get_device_name(0))
            #     print('Memory Usage:')
            #     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')
            #     print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')
            epoch_end=time.time()
            print('time taken for epoch '+str(epoch)+' is ' + str( epoch_end-epoch_start ))
    train_end=time.time()
    print('time taken to train = ' + str( train_end-train_start ))
    return model,train_loss_epoch,val_loss_epoch,train_dice_epoch,val_dice_epoch

optimizer = optim.Adam(u.parameters(), lr=0.001, betas=(0.9,0.999))
# checkpoint = torch.load('/content/drive/MyDrive/Computer Vision/Latest CV_vamsh/Segmentation_Data/cropped/weights/cp/adam.pt')
# u.load_state_dict(checkpoint['model_state_dict'])
# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
# epoch = checkpoint['epoch']
# loss = checkpoint['loss']
# optimizer= optim.SGD(u.parameters(),lr=0.01,momentum=0.9)
model,trainloss,vallloss,traindice,valdice=train(u,200,32)
